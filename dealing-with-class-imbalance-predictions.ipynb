{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c17d673",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-03-23T13:25:27.310365Z",
     "iopub.status.busy": "2023-03-23T13:25:27.309341Z",
     "iopub.status.idle": "2023-03-23T13:25:37.685366Z",
     "shell.execute_reply": "2023-03-23T13:25:37.684192Z"
    },
    "papermill": {
     "duration": 10.390436,
     "end_time": "2023-03-23T13:25:37.688535",
     "exception": false,
     "start_time": "2023-03-23T13:25:27.298099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /usr/share/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import re\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59e3c47",
   "metadata": {
    "papermill": {
     "duration": 0.007977,
     "end_time": "2023-03-23T13:25:37.705203",
     "exception": false,
     "start_time": "2023-03-23T13:25:37.697226",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center><span style=\"color:#800000;\"> DATA PREPROCESSING </span></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d3b78a",
   "metadata": {
    "papermill": {
     "duration": 0.007864,
     "end_time": "2023-03-23T13:25:37.721173",
     "exception": false,
     "start_time": "2023-03-23T13:25:37.713309",
     "status": "completed"
    },
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "410c126b",
   "metadata": {
    "papermill": {
     "duration": 0.007794,
     "end_time": "2023-03-23T13:25:37.737117",
     "exception": false,
     "start_time": "2023-03-23T13:25:37.729323",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Data Preprocessing part 1: \n",
    "1. Drop Columns: salary_range, department. <br>\n",
    "2. Add country, state for each entry and calculate percentage of fake jobs based on state. \n",
    "3. Fill the NaN values with blank spaces in the textual \n",
    "4. Create a text column with all the textual categories and drop them from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a9b47d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:25:37.757000Z",
     "iopub.status.busy": "2023-03-23T13:25:37.755399Z",
     "iopub.status.idle": "2023-03-23T13:25:40.139322Z",
     "shell.execute_reply": "2023-03-23T13:25:40.138350Z"
    },
    "papermill": {
     "duration": 2.396778,
     "end_time": "2023-03-23T13:25:40.142099",
     "exception": false,
     "start_time": "2023-03-23T13:25:37.745321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/kaggle/input/real-or-fake-fake-jobposting-prediction/fake_job_postings.csv\")\n",
    "data.drop([\"salary_range\", \"department\"], axis='columns', inplace = True)\n",
    "\n",
    "#function to  get the country where the job is posted \n",
    "def country(text):\n",
    "    if type(text) != float: #location is not null\n",
    "         return text.split(',')[0]\n",
    "    else: return ' '\n",
    "\n",
    "#adding a column to the original dataset with the country where the job is posted    \n",
    "data['country'] = data.location.apply(country)\n",
    "\n",
    "# Creating a new dataset with jobs posted only in the US\n",
    "data_US = data[data[\"country\"] == 'US']\n",
    "data_US = data_US.reset_index()\n",
    "data_US.drop('index', axis = 'columns', inplace = True)\n",
    "\n",
    "#Adding a column that indicates the state where the job was posted\n",
    "def state(text):\n",
    "    if len(text) > 3: return text.split(',')[1]\n",
    "    else: return ' '    \n",
    "\n",
    "data_US['state'] = data_US.location.apply(state)\n",
    "#Creating two seperate datasets for real jobs and fake jobs in the US\n",
    "data_US_fake = data_US[data_US['fraudulent'] == 1]\n",
    "# Creating a new attribute, for each state we calculate the pecentage of fake jobs\n",
    "state_df = data_US.state.value_counts().to_frame().rename(columns = {'state' : 'no of jobs'})\n",
    "state_df['no of fake jobs'] = data_US_fake.state.value_counts()\n",
    "state_df['p_fake_jobs'] = (state_df['no of fake jobs'] / state_df['no of jobs'])\n",
    "#adding a new column to the US dataset, a percentage of fake jobs \n",
    "state_df.drop(' ', axis = 'index', inplace = True)\n",
    "states_percentage = state_df['p_fake_jobs'].to_dict()  #creating a dictionary with each state and the percentage of fake jobs to add the  value to the dataset\n",
    "data_US['percentage of fake jobs'] = data_US['state'].map(states_percentage)\n",
    "\n",
    "#Creating a column with all the textual data\n",
    "data_US_text = data_US[['title', 'location', 'company_profile', 'description', 'requirements', 'benefits',\n",
    "                        'employment_type', 'required_experience','required_education', 'industry', 'function', 'fraudulent']]\n",
    "data_US_text = data_US_text.fillna(' ')\n",
    "data_US_text['text'] = data_US_text['title'] + ' ' + data_US_text['location'] + ' ' + data_US_text['company_profile'] + ' '+ data_US_text['description'] + ' '+ data_US_text['requirements'] + ' '+ data_US_text['benefits'] + ' '+ data_US_text['employment_type'] + ' '+ data_US_text['required_experience'] + ' ' + data_US_text['required_education'] + ' '+ data_US_text['industry'] + ' ' + data_US_text['function']\n",
    "data_US_text.drop(columns = ['title', 'location', 'company_profile', 'description', 'requirements', 'benefits',\n",
    "                        'employment_type', 'required_experience','required_education', 'industry', 'function' ], inplace = True)\n",
    "\n",
    "data_US_text_real = data_US_text[data_US_text['fraudulent'] == 0]\n",
    "data_US_text_fake = data_US_text[data_US_text['fraudulent'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eab83596",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:25:40.162367Z",
     "iopub.status.busy": "2023-03-23T13:25:40.161330Z",
     "iopub.status.idle": "2023-03-23T13:25:40.847275Z",
     "shell.execute_reply": "2023-03-23T13:25:40.846227Z"
    },
    "papermill": {
     "duration": 0.698262,
     "end_time": "2023-03-23T13:25:40.850055",
     "exception": false,
     "start_time": "2023-03-23T13:25:40.151793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_US_text.to_csv('data_US_text_not_clean.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c3281c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-15T12:39:26.419101Z",
     "iopub.status.busy": "2023-03-15T12:39:26.418659Z",
     "iopub.status.idle": "2023-03-15T12:39:26.435247Z",
     "shell.execute_reply": "2023-03-15T12:39:26.433732Z",
     "shell.execute_reply.started": "2023-03-15T12:39:26.419063Z"
    },
    "papermill": {
     "duration": 0.00813,
     "end_time": "2023-03-23T13:25:40.866697",
     "exception": false,
     "start_time": "2023-03-23T13:25:40.858567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Data Preprocessing part 2: \n",
    "1. Convert to lower case.\n",
    "2. Clean text from punctuation, numbers, links (https), symbols etc.\n",
    "3. Clean text from stopwords.\n",
    "4. Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c718c92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:25:40.886593Z",
     "iopub.status.busy": "2023-03-23T13:25:40.886173Z",
     "iopub.status.idle": "2023-03-23T13:27:36.028561Z",
     "shell.execute_reply": "2023-03-23T13:27:36.027507Z"
    },
    "papermill": {
     "duration": 115.155388,
     "end_time": "2023-03-23T13:27:36.031546",
     "exception": false,
     "start_time": "2023-03-23T13:25:40.876158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def clean_text(row):\n",
    "    t = row['text']\n",
    "    #Lower case\n",
    "    t = t.lower()\n",
    "    #Removing punctuation, links, numbers, _/-/@/% etc. \n",
    "    t = re.sub(r\"(@\\[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|[0-9]|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", t)\n",
    "    #Removing the extra spaces created \n",
    "    t = re.sub(' +', ' ', t)\n",
    "    #English stopwords are removed\n",
    "    fulltext = t.split()\n",
    "    stop = stopwords.words('english')\n",
    "    t = \" \".join([w for w in fulltext if w not in (stop)])\n",
    "    #Stemming\n",
    "    fulltext_stem = []\n",
    "    stemmer = PorterStemmer()\n",
    "    for w in fulltext:\n",
    "        fulltext_stem.append(stemmer.stem(w))\n",
    "\n",
    "    return ' '.join(s for s in fulltext_stem)\n",
    "\n",
    "data_US_text['clean_text'] = data_US_text.apply(clean_text, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e7068a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:27:36.051361Z",
     "iopub.status.busy": "2023-03-23T13:27:36.050361Z",
     "iopub.status.idle": "2023-03-23T13:27:37.199248Z",
     "shell.execute_reply": "2023-03-23T13:27:37.198340Z"
    },
    "papermill": {
     "duration": 1.161691,
     "end_time": "2023-03-23T13:27:37.201898",
     "exception": false,
     "start_time": "2023-03-23T13:27:36.040207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_US_text.to_csv('data_US_text.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e16741ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:27:37.221042Z",
     "iopub.status.busy": "2023-03-23T13:27:37.220452Z",
     "iopub.status.idle": "2023-03-23T13:27:37.845350Z",
     "shell.execute_reply": "2023-03-23T13:27:37.843771Z"
    },
    "papermill": {
     "duration": 0.637553,
     "end_time": "2023-03-23T13:27:37.848070",
     "exception": false,
     "start_time": "2023-03-23T13:27:37.210517",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_b = pd.read_csv(\"/kaggle/working/data_US_text.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f0448b7",
   "metadata": {
    "papermill": {
     "duration": 0.007888,
     "end_time": "2023-03-23T13:27:37.864731",
     "exception": false,
     "start_time": "2023-03-23T13:27:37.856843",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "##### Converting to numerical form and spitting train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb49195c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:27:37.883548Z",
     "iopub.status.busy": "2023-03-23T13:27:37.882466Z",
     "iopub.status.idle": "2023-03-23T13:28:14.253723Z",
     "shell.execute_reply": "2023-03-23T13:28:14.252499Z"
    },
    "papermill": {
     "duration": 36.391157,
     "end_time": "2023-03-23T13:28:14.264068",
     "exception": false,
     "start_time": "2023-03-23T13:27:37.872911",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7459, 93480)\n",
      "(3197, 93480)\n",
      "(7459,)\n",
      "(3197,)\n"
     ]
    }
   ],
   "source": [
    "def ready_for_training(text, y, ngram, bbool):\n",
    "    #Converting the textual data into numerical form to feed to the predicting models, using the Bag of Words approach\n",
    "    vec = CountVectorizer(ngram_range = ngram, binary = bbool)\n",
    "    X = vec.fit_transform(text).toarray() #X = vec.fit_transform(data_US_text['clean_text']).toarray()\n",
    "    #The BoW approach gives each word a score based on its occurence in the text, but does not take into consideration how\n",
    "    #frequent this word is in all the texts, thus I use TF-IDF that considers the all the texts to assign a weightage to a word.\n",
    "    tfidf = TfidfTransformer()\n",
    "    X = tfidf.fit_transform(X).toarray()    \n",
    "    return train_test_split(X, y, test_size = 0.3, random_state=0) #splitting to train/test\n",
    "\n",
    "X_train, X_test, y_train, y_test = ready_for_training(data_b['clean_text'], data_b.fraudulent,(1,1), False)\n",
    "#considering bigrams (1,2) the session crashes. \n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022ba5f",
   "metadata": {
    "papermill": {
     "duration": 0.00832,
     "end_time": "2023-03-23T13:28:14.281692",
     "exception": false,
     "start_time": "2023-03-23T13:28:14.273372",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf77131",
   "metadata": {
    "papermill": {
     "duration": 0.008093,
     "end_time": "2023-03-23T13:28:14.298329",
     "exception": false,
     "start_time": "2023-03-23T13:28:14.290236",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <center><span style=\"color:#800000;\"> PREDICTIONS</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c617d0d8",
   "metadata": {
    "papermill": {
     "duration": 0.009857,
     "end_time": "2023-03-23T13:28:14.316574",
     "exception": false,
     "start_time": "2023-03-23T13:28:14.306717",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4169E1;\">1. Random Forest\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd6c28e",
   "metadata": {
    "papermill": {
     "duration": 0.008519,
     "end_time": "2023-03-23T13:28:14.334481",
     "exception": false,
     "start_time": "2023-03-23T13:28:14.325962",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4169E1;\">1.1. Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b53d2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:28:14.353329Z",
     "iopub.status.busy": "2023-03-23T13:28:14.352904Z",
     "iopub.status.idle": "2023-03-23T13:28:56.507608Z",
     "shell.execute_reply": "2023-03-23T13:28:56.506064Z"
    },
    "papermill": {
     "duration": 42.172103,
     "end_time": "2023-03-23T13:28:56.515005",
     "exception": false,
     "start_time": "2023-03-23T13:28:14.342902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest With Class Weighting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      2998\n",
      "           1       1.00      0.49      0.66       199\n",
      "\n",
      "    accuracy                           0.97      3197\n",
      "   macro avg       0.98      0.75      0.82      3197\n",
      "weighted avg       0.97      0.97      0.96      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest With Class Weighting')\n",
    "\n",
    "classifier = RandomForestClassifier(class_weight='balanced')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ebc78e",
   "metadata": {
    "papermill": {
     "duration": 0.013144,
     "end_time": "2023-03-23T13:28:56.538075",
     "exception": false,
     "start_time": "2023-03-23T13:28:56.524931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4169E1;\">1.2. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebdb1bb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:28:56.564001Z",
     "iopub.status.busy": "2023-03-23T13:28:56.563169Z",
     "iopub.status.idle": "2023-03-23T13:28:57.159175Z",
     "shell.execute_reply": "2023-03-23T13:28:57.157899Z"
    },
    "papermill": {
     "duration": 0.612319,
     "end_time": "2023-03-23T13:28:57.162155",
     "exception": false,
     "start_time": "2023-03-23T13:28:56.549836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "#For example, if we set sampling_strategy to 0.5 in an imbalanced data dataset with 1,000 examples in the majority class and 100 examples in the minority class, then there would be 200 examples for the majority class in the transformed dataset (or 100/200 = 0.5).\n",
    "undersample1 = RandomUnderSampler(sampling_strategy=0.5)\n",
    "X_under, y_under = undersample.fit_resample(X_train, y_train)\n",
    "X_under1, y_under1 = undersample1.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a21aea88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:28:57.182359Z",
     "iopub.status.busy": "2023-03-23T13:28:57.181195Z",
     "iopub.status.idle": "2023-03-23T13:29:03.933384Z",
     "shell.execute_reply": "2023-03-23T13:29:03.931975Z"
    },
    "papermill": {
     "duration": 6.765148,
     "end_time": "2023-03-23T13:29:03.936076",
     "exception": false,
     "start_time": "2023-03-23T13:28:57.170928",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with UnderSampling\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.90      0.94      2998\n",
      "           1       0.38      0.92      0.53       199\n",
      "\n",
      "    accuracy                           0.90      3197\n",
      "   macro avg       0.69      0.91      0.74      3197\n",
      "weighted avg       0.96      0.90      0.92      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with UnderSampling')\n",
    "classifier = RandomForestClassifier()\n",
    "classifier.fit(X_under, y_under)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6613f80c",
   "metadata": {
    "papermill": {
     "duration": 0.008602,
     "end_time": "2023-03-23T13:29:03.953528",
     "exception": false,
     "start_time": "2023-03-23T13:29:03.944926",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Using the above undersampling technique for random forest, we see that our recall value for the original minority class increases incredibly to a 0.91, however, our precision is lowered to 0.41, the lowest value I have seen so far for this prediction problem. This can be explained as the model is predicting a lot more cases as fake jobs, even cases that are in fact not fake. Thus, the recall score also increasesas the model is predicting as positive a larger percentage of the overall fake jobs. On the other side, the recall score for real jobs is relatively lower as the ratio of the rightfully predicted real jobs over all real jobs in the dataset is smaller.\n",
    "<br>\n",
    "**This is due to the undersampling method loosing valuable information from the majority class to balance the dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed9ec10e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:29:03.972464Z",
     "iopub.status.busy": "2023-03-23T13:29:03.972038Z",
     "iopub.status.idle": "2023-03-23T13:29:15.059877Z",
     "shell.execute_reply": "2023-03-23T13:29:15.058365Z"
    },
    "papermill": {
     "duration": 11.101324,
     "end_time": "2023-03-23T13:29:15.063420",
     "exception": false,
     "start_time": "2023-03-23T13:29:03.962096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest with UnderSampling to 0.5 ratio majority/minority\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      2998\n",
      "           1       0.91      0.71      0.80       199\n",
      "\n",
      "    accuracy                           0.98      3197\n",
      "   macro avg       0.95      0.85      0.89      3197\n",
      "weighted avg       0.98      0.98      0.98      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest with UnderSampling to 0.5 ratio majority/minority')\n",
    "classifier.fit(X_under1, y_under1)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698cb7ff",
   "metadata": {
    "papermill": {
     "duration": 0.008574,
     "end_time": "2023-03-23T13:29:15.081467",
     "exception": false,
     "start_time": "2023-03-23T13:29:15.072893",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**In this case I chose to rather than balance the number of real and fake jobs, to undersample the majority class to a 1/2 ration of majority/minority class. This way it can be observed an imporved f1-score better than the Logistic Regression and Random Forest previously used on the origical imbalanced data. This significantly performs better than the previous undersampling method as it increasies by 50% the amount of data to train the model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781929c3",
   "metadata": {
    "papermill": {
     "duration": 0.008611,
     "end_time": "2023-03-23T13:29:15.099018",
     "exception": false,
     "start_time": "2023-03-23T13:29:15.090407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f8da87",
   "metadata": {
    "papermill": {
     "duration": 0.008485,
     "end_time": "2023-03-23T13:29:15.116438",
     "exception": false,
     "start_time": "2023-03-23T13:29:15.107953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4169E1;\">2. LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee8b129",
   "metadata": {
    "papermill": {
     "duration": 0.008466,
     "end_time": "2023-03-23T13:29:15.133648",
     "exception": false,
     "start_time": "2023-03-23T13:29:15.125182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4169E1;\">2.1. Class Weighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e63e0c01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:29:15.153607Z",
     "iopub.status.busy": "2023-03-23T13:29:15.152764Z",
     "iopub.status.idle": "2023-03-23T13:29:43.830169Z",
     "shell.execute_reply": "2023-03-23T13:29:43.826111Z"
    },
    "papermill": {
     "duration": 28.692466,
     "end_time": "2023-03-23T13:29:43.834878",
     "exception": false,
     "start_time": "2023-03-23T13:29:15.142412",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR With Class Weighting\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98      2998\n",
      "           1       0.73      0.87      0.79       199\n",
      "\n",
      "    accuracy                           0.97      3197\n",
      "   macro avg       0.86      0.92      0.89      3197\n",
      "weighted avg       0.97      0.97      0.97      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('LR With Class Weighting')\n",
    "\n",
    "classifier = LogisticRegression(class_weight='balanced')\n",
    "classifier.fit(X_train, y_train)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab04b239",
   "metadata": {
    "papermill": {
     "duration": 0.023067,
     "end_time": "2023-03-23T13:29:43.882682",
     "exception": false,
     "start_time": "2023-03-23T13:29:43.859615",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4169E1;\">2.2. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a3637422",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:29:43.930702Z",
     "iopub.status.busy": "2023-03-23T13:29:43.930260Z",
     "iopub.status.idle": "2023-03-23T13:29:50.435380Z",
     "shell.execute_reply": "2023-03-23T13:29:50.433671Z"
    },
    "papermill": {
     "duration": 6.537628,
     "end_time": "2023-03-23T13:29:50.443478",
     "exception": false,
     "start_time": "2023-03-23T13:29:43.905850",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression with UnderSampling to 0.5 ratio majority/minority\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2998\n",
      "           1       0.85      0.72      0.78       199\n",
      "\n",
      "    accuracy                           0.97      3197\n",
      "   macro avg       0.92      0.86      0.88      3197\n",
      "weighted avg       0.97      0.97      0.97      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Logistic Regression with UnderSampling to 0.5 ratio majority/minority')\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_under1, y_under1)\n",
    "y_pred = classifier.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d81b52",
   "metadata": {
    "papermill": {
     "duration": 0.02488,
     "end_time": "2023-03-23T13:29:50.494273",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.469393",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Using the same undersampling technique on the training data before using Logistic Regression, we see a big improvement in performance, f-1 score for fake jobs prediction is increased from 0.56 (original imbalanced data) to 0.80 (undersampled data).**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228e31b1",
   "metadata": {
    "papermill": {
     "duration": 0.016181,
     "end_time": "2023-03-23T13:29:50.539847",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.523666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"font-size:18px;\" >USING UNDERSAMPLING METHOD WITH 0.5 RATIO IS THE BEST METHOD FOUND TO INCREASE PERFORMANCE WITH THE LOGISTIC REGRESSION AND RANDOM FOREST CLASSIFIER METHODS. üòÅ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67de8426",
   "metadata": {
    "papermill": {
     "duration": 0.009037,
     "end_time": "2023-03-23T13:29:50.558693",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.549656",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<span style=\"color:#800000;font-size:22px;\" >However I was not able to improve the performance of these models enough to perform better than the Neural Network used previously. Thus, below I am going to work on improving the performance of the Neural Network model. </span> ‚¨áÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e7d4f6",
   "metadata": {
    "papermill": {
     "duration": 0.009153,
     "end_time": "2023-03-23T13:29:50.577047",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.567894",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85f109b",
   "metadata": {
    "papermill": {
     "duration": 0.009109,
     "end_time": "2023-03-23T13:29:50.595769",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.586660",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4169E1;\">3. Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4629c77",
   "metadata": {
    "papermill": {
     "duration": 0.009147,
     "end_time": "2023-03-23T13:29:50.614360",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.605213",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4169E1;\">3.1. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8f70bc14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:29:50.634838Z",
     "iopub.status.busy": "2023-03-23T13:29:50.634424Z",
     "iopub.status.idle": "2023-03-23T13:30:36.701945Z",
     "shell.execute_reply": "2023-03-23T13:30:36.700716Z"
    },
    "papermill": {
     "duration": 46.081054,
     "end_time": "2023-03-23T13:30:36.704808",
     "exception": false,
     "start_time": "2023-03-23T13:29:50.623754",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 50)                4674050   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                465       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,676,061\n",
      "Trainable params: 4,676,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "128/128 [==============================] - 6s 36ms/step - loss: 0.4415 - accuracy: 0.8265 - val_loss: 1.1956 - val_accuracy: 0.0282\n",
      "Epoch 2/10\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 0.1548 - accuracy: 0.9396 - val_loss: 0.9278 - val_accuracy: 0.6646\n",
      "Epoch 3/10\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.6057 - val_accuracy: 0.7367\n",
      "Epoch 4/10\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 1.4088 - val_accuracy: 0.6176\n",
      "Epoch 5/10\n",
      "128/128 [==============================] - 5s 35ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.7955 - val_accuracy: 0.7335\n",
      "Epoch 6/10\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 9.3693e-04 - accuracy: 1.0000 - val_loss: 0.9066 - val_accuracy: 0.7210\n",
      "Epoch 7/10\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 2.7994e-04 - accuracy: 1.0000 - val_loss: 0.9093 - val_accuracy: 0.7241\n",
      "Epoch 8/10\n",
      "128/128 [==============================] - 4s 33ms/step - loss: 1.9799e-04 - accuracy: 1.0000 - val_loss: 0.9137 - val_accuracy: 0.7241\n",
      "Epoch 9/10\n",
      "128/128 [==============================] - 5s 36ms/step - loss: 1.4842e-04 - accuracy: 1.0000 - val_loss: 0.9151 - val_accuracy: 0.7304\n",
      "Epoch 10/10\n",
      "128/128 [==============================] - 4s 34ms/step - loss: 1.1607e-04 - accuracy: 1.0000 - val_loss: 0.9284 - val_accuracy: 0.7304\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(X_under1.shape[1],), activation='relu')) \n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary() \n",
    "\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "\n",
    "#no neeed for early stopping, no of epoch small\n",
    "history = model.fit(X_under1, y_under1,\n",
    "                    epochs=10, \n",
    "                    batch_size=10,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d0f5fa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:30:36.812719Z",
     "iopub.status.busy": "2023-03-23T13:30:36.811733Z",
     "iopub.status.idle": "2023-03-23T13:30:39.713461Z",
     "shell.execute_reply": "2023-03-23T13:30:39.712079Z"
    },
    "papermill": {
     "duration": 2.958795,
     "end_time": "2023-03-23T13:30:39.715742",
     "exception": false,
     "start_time": "2023-03-23T13:30:36.756947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      2998\n",
      "           1       0.83      0.77      0.80       199\n",
      "\n",
      "    accuracy                           0.98      3197\n",
      "   macro avg       0.91      0.88      0.89      3197\n",
      "weighted avg       0.98      0.98      0.98      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(model.predict(X_test),0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67341d8c",
   "metadata": {
    "papermill": {
     "duration": 0.052363,
     "end_time": "2023-03-23T13:30:39.820998",
     "exception": false,
     "start_time": "2023-03-23T13:30:39.768635",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4169E1;\">3.2. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b55e07c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:30:39.929318Z",
     "iopub.status.busy": "2023-03-23T13:30:39.928109Z",
     "iopub.status.idle": "2023-03-23T13:35:06.184989Z",
     "shell.execute_reply": "2023-03-23T13:35:06.183167Z"
    },
    "papermill": {
     "duration": 266.314128,
     "end_time": "2023-03-23T13:35:06.188032",
     "exception": false,
     "start_time": "2023-03-23T13:30:39.873904",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 50)                4674050   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 30)                1530      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 15)                465       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 1)                 16        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,676,061\n",
      "Trainable params: 4,676,061\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "597/597 [==============================] - 29s 47ms/step - loss: 0.6551 - accuracy: 0.9157 - val_loss: 0.2030 - val_accuracy: 0.9216\n",
      "Epoch 2/10\n",
      "597/597 [==============================] - 20s 34ms/step - loss: 0.0764 - accuracy: 0.9864 - val_loss: 0.0683 - val_accuracy: 0.9732\n",
      "Epoch 3/10\n",
      "597/597 [==============================] - 21s 34ms/step - loss: 0.0088 - accuracy: 0.9987 - val_loss: 0.0615 - val_accuracy: 0.9772\n",
      "Epoch 4/10\n",
      "597/597 [==============================] - 20s 33ms/step - loss: 0.0040 - accuracy: 0.9995 - val_loss: 0.0646 - val_accuracy: 0.9772\n",
      "Epoch 5/10\n",
      "597/597 [==============================] - 19s 32ms/step - loss: 7.5405e-04 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "597/597 [==============================] - 20s 33ms/step - loss: 0.0014 - accuracy: 0.9997 - val_loss: 0.0701 - val_accuracy: 0.9772\n",
      "Epoch 7/10\n",
      "597/597 [==============================] - 20s 33ms/step - loss: 0.0010 - accuracy: 0.9998 - val_loss: 0.0736 - val_accuracy: 0.9786\n",
      "Epoch 8/10\n",
      "597/597 [==============================] - 20s 34ms/step - loss: 9.9650e-05 - accuracy: 1.0000 - val_loss: 0.0773 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "597/597 [==============================] - 20s 34ms/step - loss: 4.8035e-05 - accuracy: 1.0000 - val_loss: 0.0811 - val_accuracy: 0.9779\n",
      "Epoch 10/10\n",
      "597/597 [==============================] - 19s 33ms/step - loss: 2.5697e-05 - accuracy: 1.0000 - val_loss: 0.0849 - val_accuracy: 0.9779\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(50, input_shape=(X_train.shape[1],), activation='relu')) \n",
    "model.add(Dense(30, activation='relu'))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary() \n",
    "weights = {0:1, 1:13}\n",
    "model.compile(optimizer='Adam', loss='binary_crossentropy',  metrics=['accuracy'])\n",
    "\n",
    "#no neeed for early stopping, no of epoch small\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=10, \n",
    "                    batch_size=10,\n",
    "                    class_weight = weights,\n",
    "                    validation_split=0.2,\n",
    "                    shuffle=True,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c8a7f77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-03-23T13:35:06.697976Z",
     "iopub.status.busy": "2023-03-23T13:35:06.697078Z",
     "iopub.status.idle": "2023-03-23T13:35:10.175247Z",
     "shell.execute_reply": "2023-03-23T13:35:10.173008Z"
    },
    "papermill": {
     "duration": 3.735763,
     "end_time": "2023-03-23T13:35:10.177759",
     "exception": false,
     "start_time": "2023-03-23T13:35:06.441996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 1s 11ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      2998\n",
      "           1       0.82      0.84      0.83       199\n",
      "\n",
      "    accuracy                           0.98      3197\n",
      "   macro avg       0.91      0.91      0.91      3197\n",
      "weighted avg       0.98      0.98      0.98      3197\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.round(model.predict(X_test),0)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41de17c",
   "metadata": {
    "papermill": {
     "duration": 0.284663,
     "end_time": "2023-03-23T13:35:10.716635",
     "exception": false,
     "start_time": "2023-03-23T13:35:10.431972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 597.099734,
   "end_time": "2023-03-23T13:35:14.685265",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-03-23T13:25:17.585531",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
